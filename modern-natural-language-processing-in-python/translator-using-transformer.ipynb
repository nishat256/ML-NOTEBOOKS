{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "NUM_SAMPLES = 10000 # number of sample to train on\n",
    "MAX_NUM_WORDS = 20000\n",
    "MAX_SEQ_LEN = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples : 2869\n"
     ]
    }
   ],
   "source": [
    "# processing dataset \n",
    "input_texts = []\n",
    "target_texts_output = []\n",
    "target_texts_input = []\n",
    "\n",
    "t=0\n",
    "for line in open('data/eng_to_hindi.txt',encoding='utf-8'):\n",
    "    t+=1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    input_text, translation = line.split('\\t')\n",
    "    target_text_output = translation.strip() + ' <eos>'\n",
    "    target_text_input = '<sos> '+ translation.strip()\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts_output.append(target_text_output)\n",
    "    target_texts_input.append(target_text_input)\n",
    "print(\"number of samples : {}\".format(len(input_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokkens in inputs : 2402\n",
      "22\n",
      "Unique tokkens in outputs : 3161\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# tokenizing sentences \n",
    "#input\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Unique tokkens in inputs : {}'.format(len(word2idx_inputs)))\n",
    "max_len_input = max([len(s) for s in input_sequences])\n",
    "print(max_len_input)\n",
    "\n",
    "#output\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS,filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts_output+target_texts_input)\n",
    "target_sequences_input = tokenizer_outputs.texts_to_sequences(target_texts_input)\n",
    "target_sequences_output = tokenizer_outputs.texts_to_sequences(target_texts_output)\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Unique tokkens in outputs : {}'.format(len(word2idx_outputs)))\n",
    "max_len_target = max([len(s) for s in target_sequences_input])\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "print(max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder shape : (2869, 26)\n",
      "encoder_data[0] s: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 90]\n",
      "decoder input shape : (2869, 26)\n",
      "decoder_input_data[0] s: [   2 1500    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "decoder output shape : (2869, 26)\n",
      "decoder_output_data[0] s: [1500    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# pad sequences\n",
    "encoder_inputs = pad_sequences(input_sequences,maxlen=MAX_SEQ_LEN)\n",
    "print(\"encoder shape :\",encoder_inputs.shape)\n",
    "print(\"encoder_data[0] s:\",encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_input,maxlen=MAX_SEQ_LEN, padding='post')\n",
    "print(\"decoder input shape :\",decoder_inputs.shape)\n",
    "print(\"decoder_input_data[0] s:\",decoder_inputs[0])\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences_output,maxlen=MAX_SEQ_LEN, padding='post')\n",
    "print(\"decoder output shape :\",decoder_targets.shape)\n",
    "print(\"decoder_output_data[0] s:\",decoder_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        \n",
    "    def get_angles(self,pos,i,d_model):#pos : (seq_len ,1)  i : (1,d_model)\n",
    "        angles = 1 / np.power(10000.0,(2*(i//2))/np.float32(d_model))\n",
    "        return pos * angles # (seq_len , d_model)\n",
    "    \n",
    "    def __call__(self,inputs):\n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "        angles = self.get_angles(np.arange(seq_length)[:,np.newaxis],\n",
    "                                 np.arange(d_model)[np.newaxis,:],\n",
    "                                 d_model)\n",
    "        angles[:,0::2] = np.sin(angles[:,0::2] ) \n",
    "        angles[:,1::2] = np.cos(angles[:,1::2] ) \n",
    "        pos_encoding = angles[np.newaxis,...]\n",
    "        \n",
    "        return inputs + tf.cast(pos_encoding,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(queris,keys,values,mask):\n",
    "    product = tf.matmul(queris,keys,b_transpose=True)\n",
    "    \n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1],tf.float32)\n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_product += mask*(-1e9)\n",
    "    \n",
    "    attention = tf.matmal(tf.nn.softmax(scaled_product, axis=-1), values)\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    def ___init__(self,nb_proj):\n",
    "        super(self,MultiHeadAttention).__init__()\n",
    "        self.nb_proj = nb_proj\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        assert self.d_model % self.nb_proj == 0\n",
    "        self.d_proj = self.d_model / self.nb_proj\n",
    "        \n",
    "        self.query_lin = layers.Dense(units=self.d_model)\n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "        self.val_lin = layers.Dense(units=self.d_model)\n",
    "        \n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "        \n",
    "    def split_proj(self,inputs, batch_size): # inputs : (batch_size,seq_len,d_model)\n",
    "        shape = (batch_size,\n",
    "                 -1,\n",
    "                 self.nb_proj,\n",
    "                 self.d_proj)\n",
    "        \n",
    "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_len, nb_proj,d_proj)\n",
    "        return tf.transpose(splited_inputs,perm=[0,2,1,3]) # (batch_size,nb_proj,seq_len,d_proj)\n",
    "        \n",
    "    def __call__(self,queries,keys,values,mask):\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "        queries = self.query_lin(queries)\n",
    "        keys = self.key_lin(keys)\n",
    "        values = self.val_lin(values)\n",
    "        \n",
    "        queries = self.split_proj(queries,batch_size)\n",
    "        keys = self.split_proj(keys,batch_size)\n",
    "        values = self.split_proj(values,batch_size)\n",
    "        \n",
    "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
    "        \n",
    "        attention = tf.transpose(attention, perm=[0,2,1,3])\n",
    "        \n",
    "        concat_attention = tf.reshape(attention,\n",
    "                                           shape=(batch_size,-1,self.d_model))\n",
    "        \n",
    "        output = self.final_lin(concat_attention)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self,FFN_units,nb_proj,dropout):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.nb_prob = nb_proj\n",
    "        self.FFN_units = FFN_units\n",
    "        self.dropout = dropout \n",
    "        self.multi_head_attention1 = MultiHeadAttention(self.nb_prob)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        \n",
    "        self.dropout_1 = layers.Dropout(rate=self.dorpout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_2 =  layers.Dropout(rate=self.dorpout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    def __call__(self,inputs, mask):\n",
    "        attention = self.multi_head_attention1(inputs, inputs, inputs, mask)\n",
    "        attention = self.dropout_1(attention)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        outputs = self.dense_1(attention)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_2(outputs)\n",
    "        outputs = self.norm_2(attention + outputs)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name='encoder'):\n",
    "        super(Encoder,self).__init__(name=name)\n",
    "        self.nb_layers = nb_layers\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size,d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        self.enc_layers = [EncoderLayer(FFN_units,nb_proj,dropout) for _ in range(self.nb_layers)]\n",
    "        \n",
    "    def __call__(self,inputs,mask):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self,FFN_units,nb_proj,dropout):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_prob)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_prob)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=d_model)\n",
    "        self.dropout_3 =  layers.Dropout(rate=self.dropout)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def __call__(self,inputs,enc_outputs,mask_1,mask_2):\n",
    "        attention = self.multi_head_attention_1(inputs,inputs,inputs,mask_1)\n",
    "        attention = self.dropout_1(attention)\n",
    "        attention = self.norm_1(inputs + attention)\n",
    "        \n",
    "        attention_2 = self.multi_head_attention_2(attention,enc_outputs,enc_outputs,mask_2)\n",
    "        attention_2 = self.dropout_2(attention_2)\n",
    "        attention_2 = self.norm_2(attention + attention_2)\n",
    "        \n",
    "        outputs = self.dense_1(attention_2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs)\n",
    "        outputs = self.norm_3(attention_2 + outputs)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name='decoder'):\n",
    "        super(Decoder,self).__init__(name=name)\n",
    "        self.nb_layers = nb_layers\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(FFN_units,nb_proj,dropout) for _ in range(self.nb_layers)]\n",
    "        \n",
    "    def __call__(self,inputs,enc_outputs,mask_1,mask_2):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.dec_layers[i](outputs,enc_outputs,mask_1,mask_2)\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size_enc,\n",
    "                 vocab_size_dec,\n",
    "                 d_model,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 name='transformer'):\n",
    "        super(Transformer,self).__init__(name=name)\n",
    "        \n",
    "        self.encoder = Encoder(nb_layers,\n",
    "                               FFN_units,\n",
    "                               nb_proj,\n",
    "                               dropout,\n",
    "                               vocab_size_enc,\n",
    "                               d_model)\n",
    "        \n",
    "        self.decoder = Decoder(nb_layers,\n",
    "                               FFN_units,\n",
    "                               nb_proj,\n",
    "                               dropout,\n",
    "                               vocab_size_dec,\n",
    "                               d_model)\n",
    "        \n",
    "        self.last_linear = layers.Dense(units=vocab_size_dec)\n",
    "        \n",
    "    def create_padding_mask(self,seq): # seq : (batch_size,seq_len)\n",
    "        mask = tf.cast(tf.math.equal(seq,0),tf.float32)\n",
    "        return mask[:,tf.newaxis,tf.newaxis,:]\n",
    "                \n",
    "    def create_look_ahead_mask(self,seq):\n",
    "        seq_len = tf.shape(seq)[1]\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len,seq_len)),-1,0)\n",
    "        return look_ahead_mask\n",
    "    \n",
    "    def __call__(self,enc_inputs,dec_inputs):\n",
    "        enc_mask = self.create_padding_mask(enc_inputs)\n",
    "        dec_mask_1 = tf.maximum(self.create_padding_mask(dec_inputs),self.create_look_ahead_mask(dec_inputs))\n",
    "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
    "        \n",
    "        enc_outputs = self.encoder(enc_inputs, enc_mask)\n",
    "        dec_outputs = self.decoder(dec_inputs,\n",
    "                                   enc_outputs,\n",
    "                                   dec_mask_1,\n",
    "                                   dec_mask_2)\n",
    "        outputs = self.last_linear(dec_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5d4c4b67b8d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                            \u001b[0mFFN_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFFN_UNITS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                            \u001b[0mnb_proj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNB_PROJ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                            dropout=DROPOUT)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0menc_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_SEQ_LEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-8da4ff2fad51>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab_size_enc, vocab_size_dec, d_model, nb_layers, FFN_units, nb_proj, dropout, name)\u001b[0m\n\u001b[0;32m     16\u001b[0m                                \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                \u001b[0mvocab_size_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                                d_model)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         self.decoder = Decoder(nb_layers,\n",
      "\u001b[1;32m<ipython-input-18-6300864b1d4c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nb_layers, FFN_units, nb_proj, dropout, vocab_size, d_model, name)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEncoderLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFFN_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_proj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-6300864b1d4c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEncoderLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFFN_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_proj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2cf0829cfc0a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, FFN_units, nb_proj, dropout)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFFN_units\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFFN_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_head_attention1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "tf.keras.backend.clear_session()\n",
    "# hyper Parameters\n",
    "D_MODEL = 128 # 512\n",
    "NB_LAYERS = 4 # 6\n",
    "FFN_UNITS = 512 # 2048\n",
    "NB_PROJ = 8 # 8\n",
    "DROPOUT = .1 # .1\n",
    "VOCAB_SIZE_EN = len(word2idx_inputs) + 1\n",
    "VOCAB_SIZE_H = len(word2idx_outputs) + 1\n",
    "\n",
    "transformer = Transformer( vocab_size_enc=VOCAB_SIZE_EN,\n",
    "                           vocab_size_dec=VOCAB_SIZE_H,\n",
    "                           d_model=D_MODEL,\n",
    "                           nb_layers=NB_LAYERS,\n",
    "                           FFN_units=FFN_UNITS,\n",
    "                           nb_proj=NB_PROJ,\n",
    "                           dropout=DROPOUT)\n",
    "\n",
    "enc_inputs = layers.Input(shape=(MAX_SEQ_LEN,))\n",
    "dec_inputs = layers.Input(shape=(MAX_SEQ_LEN,))\n",
    "outputs = transformer(enc_inputs,dec_inputs)\n",
    "\n",
    "model = Model(inputs=[enc_inputs,dec_inputs],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
    "\n",
    "def loss_function(target,pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(target,0))\n",
    "    loss_ = loss_object(target,pred)\n",
    "    \n",
    "    mask = tf.cast(mask,dtype=loss_.dtype)\n",
    "    loss_ *=mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    def __init__(self,d_model,warmup_steps=4000):\n",
    "        super(CustomSchedule,self).__init__()\n",
    "        \n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        \n",
    "    def __call__(self,step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model*tf.minimum(arg1,arg2))\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                    beta_1=.9,\n",
    "                                    beta_2=.98,\n",
    "                                    epsilon=1e-9)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(optimizer=optimizer,loss=loss_function,metrics=train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = transformer.fit(inputs=[encoder_inputs,decoder_inputs],\n",
    "                outputs=decoder_targets,\n",
    "                batch_size = 64,\n",
    "                epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
